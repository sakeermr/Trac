name: SSC PDB Ligand Screening Pipeline - Internal

on:
  push:
    branches: [ main, master ]
    paths:
      - 'input/input_chemicals.csv'
      - 'final_optimized_workflow.py'
      - 'requirements.txt'
      - '.github/workflows/**'
  
  pull_request:
    branches: [ main, master ]
    paths:
      - 'input/input_chemicals.csv'
      - 'final_optimized_workflow.py'
      - 'requirements.txt'
  
  workflow_dispatch:
    inputs:
      input_file:
        description: 'Input CSV file path (relative to repo root)'
        required: false
        default: 'input/input_chemicals.csv'
      output_file:
        description: 'Output CSV file name'
        required: false
        default: 'ssc_screening_results.csv'
      max_pdb:
        description: 'Maximum PDB records to process (0 = all)'
        required: false
        default: '0'
      max_input:
        description: 'Maximum input chemicals to process (0 = all)'
        required: false
        default: '0'
      debug_mode:
        description: 'Enable debug mode'
        required: false
        default: 'false'
        type: choice
        options:
        - 'true'
        - 'false'

# Prevent concurrent workflow runs from causing git conflicts
concurrency:
  group: ssc-pdb-screening-${{ github.ref }}
  cancel-in-progress: false

permissions:
  contents: write
  actions: read

env:
  PYTHON_VERSION: '3.9'
  PDB_LIGANDS_FILE: 'pdb_ligands.csv'
  INPUT_CSV: ${{ github.event.inputs.input_file || 'input/input_chemicals.csv' }}
  OUTPUT_CSV: ${{ github.event.inputs.output_file || 'ssc_screening_results.csv' }}
  MAX_PDB: ${{ github.event.inputs.max_pdb || '0' }}
  MAX_INPUT: ${{ github.event.inputs.max_input || '0' }}
  DEBUG_MODE: ${{ github.event.inputs.debug_mode || 'false' }}

jobs:
  validate-input:
    name: Validate Input Files
    runs-on: ubuntu-latest
    outputs:
      input-exists: ${{ steps.check-files.outputs.input-exists }}
      pdb-exists: ${{ steps.check-files.outputs.pdb-exists }}
      input-valid: ${{ steps.validate-csv.outputs.valid }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1

    - name: Check if required files exist
      id: check-files
      run: |
        echo "Checking for required files..."
        
        if [ -f "$INPUT_CSV" ]; then
          echo "‚úÖ Input CSV file found: $INPUT_CSV"
          echo "input-exists=true" >> $GITHUB_OUTPUT
        else
          echo "‚ùå Input CSV file not found: $INPUT_CSV"
          echo "input-exists=false" >> $GITHUB_OUTPUT
        fi
        
        # Check for PDB ligands file
        if [ -f "pdb_ligands.csv" ]; then
          echo "‚úÖ PDB ligands file found: pdb_ligands.csv"
          echo "pdb-exists=true" >> $GITHUB_OUTPUT
        else
          echo "‚ùå PDB ligands file not found: pdb_ligands.csv"
          echo "pdb-exists=false" >> $GITHUB_OUTPUT
        fi

    - name: Validate CSV format
      id: validate-csv
      if: steps.check-files.outputs.input-exists == 'true'
      run: |
        echo "Validating CSV format for SSC internal system..."
        
        header=$(head -n 1 "$INPUT_CSV")
        echo "Header: $header"
        
        # Check for required columns for the final_optimized_workflow.py
        required_cols=("Plant" "Chemical Name" "Molecular Structure" "Molecule Category")
        header_check=$(echo "$header" | tr '[:upper:]' '[:lower:]')
        
        valid=true
        for col in "${required_cols[@]}"; do
          col_lower=$(echo "$col" | tr '[:upper:]' '[:lower:]')
          if [[ ! "$header_check" =~ $col_lower ]]; then
            echo "‚ùå Missing required column: $col"
            valid=false
          fi
        done
        
        if [ "$valid" = true ]; then
          echo "‚úÖ CSV format is valid for SSC screening system"
          echo "valid=true" >> $GITHUB_OUTPUT
          
          total_lines=$(wc -l < "$INPUT_CSV")
          total_chemicals=$((total_lines - 1))
          echo "Total chemicals to process: $total_chemicals"
        else
          echo "‚ùå CSV format is invalid"
          echo "valid=false" >> $GITHUB_OUTPUT
          exit 1
        fi

  run-pdb-screening:
    name: Run PDB Ligand Screening
    runs-on: ubuntu-latest
    needs: validate-input
    if: needs.validate-input.outputs.input-exists == 'true' && needs.validate-input.outputs.pdb-exists == 'true' && needs.validate-input.outputs.input-valid == 'true'
    outputs:
      total-processed: ${{ steps.run-algorithm.outputs.total_processed }}
      successful: ${{ steps.run-algorithm.outputs.successful }}
      output-file: ${{ steps.run-algorithm.outputs.output_file }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1

    - name: Verify PDB ligands database
      run: |
        # Install bc calculator for file size calculations
        sudo apt-get update && sudo apt-get install -y bc
        
        echo "üì• Verifying PDB ligands database..."
        echo "‚ÑπÔ∏è  Organization: ${{ github.repository_owner }} - Enterprise GitHub Account"
        
        # Check if PDB ligands file exists in repository
        if [ -f "pdb_ligands.csv" ]; then
          file_size=$(stat -c%s "pdb_ligands.csv")
          line_count=$(wc -l < "pdb_ligands.csv")
          ligand_count=$((line_count - 1))
          
          echo "‚úÖ PDB ligands file ready:"
          echo "   üìÅ Size: $file_size bytes ($(echo "scale=2; $file_size/1024/1024" | bc -l) MB)"
          echo "   üìä Lines: $line_count"
          echo "   üß¨ Available ligands: $ligand_count"
          
          # Validate minimum file size (should be at least 1MB for a meaningful PDB database)
          if [ $file_size -lt 1000000 ]; then
            echo "‚ö†Ô∏è  Warning: PDB file seems very small ($file_size bytes)"
            echo "‚ö†Ô∏è  This might affect screening accuracy"
            exit 1
          fi
          
          echo ""
          echo "First 3 lines:"
          head -n 3 pdb_ligands.csv
          
          # Provide information about database size
          if [ $file_size -gt 10000000 ]; then
            echo "‚úÖ Database size: $(echo "scale=1; $file_size/1024/1024" | bc -l) MB - Good size for screening"
          else
            echo "‚ÑπÔ∏è  Database size: $(echo "scale=1; $file_size/1024/1024" | bc -l) MB"
            echo "‚ÑπÔ∏è  Available ligands: $ligand_count records"
          fi
        else
          echo "‚ùå PDB ligands file not found: pdb_ligands.csv"
          echo "‚ùå Please ensure the pdb_ligands.csv file is committed to the repository"
          exit 1
        fi

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        
        # Install from requirements.txt for consistency
        if [ -f "requirements.txt" ]; then
          echo "Installing from requirements.txt..."
          pip install -r requirements.txt
        else
          echo "requirements.txt not found, installing dependencies manually..."
          pip install pandas numpy rdkit requests tqdm lxml scipy matplotlib seaborn openpyxl chardet
        fi
        
        # Verify all critical dependencies are available
        echo "Verifying dependencies..."
        python -c "import pandas; print(f'‚úÖ Pandas version: {pandas.__version__}')"
        python -c "import numpy; print(f'‚úÖ NumPy version: {numpy.__version__}')"
        python -c "import rdkit; print(f'‚úÖ RDKit version: {rdkit.__version__}')"
        python -c "import requests; print(f'‚úÖ Requests version: {requests.__version__}')"
        python -c "import tqdm; print(f'‚úÖ TQDM version: {tqdm.__version__}')"
        python -c "import chardet; print(f'‚úÖ Chardet version: {chardet.__version__}')"
        echo "‚úÖ All critical dependencies verified!"

    - name: Make screening script executable
      run: |
        chmod +x final_optimized_workflow.py

    - name: Run SSC PDB ligand screening
      id: run-algorithm
      run: |
        echo "üß¨ Starting SSC PDB ligand screening..."
        echo "Input file: $INPUT_CSV"
        echo "PDB file: $PDB_LIGANDS_FILE"
        echo "Output file: $OUTPUT_CSV"
        echo "Max PDB records: $MAX_PDB $([ "$MAX_PDB" = "0" ] && echo "(ALL RECORDS - 600,000+)" || echo "")"
        echo "Max input chemicals: $MAX_INPUT $([ "$MAX_INPUT" = "0" ] && echo "(ALL)" || echo "")"
        echo "Debug mode: $DEBUG_MODE"
        
        # Check available memory
        echo "üíæ System Resources:"
        free -h || echo "Memory info not available"
        
        # Ensure output directory exists
        mkdir -p output
        
        # Run the final optimized workflow with specified limits
        python final_optimized_workflow.py \
          --input "$INPUT_CSV" \
          --pdb "$PDB_LIGANDS_FILE" \
          --output "output/$OUTPUT_CSV" \
          --max-pdb "$MAX_PDB" \
          --max-input "$MAX_INPUT" \
          --verbose
        
        # Set outputs for the screening job
        echo "output_file=output/$OUTPUT_CSV" >> $GITHUB_OUTPUT
        echo "total_processed=processed" >> $GITHUB_OUTPUT
        echo "successful=completed" >> $GITHUB_OUTPUT

    - name: Verify output files
      run: |
        echo "üîç Verifying SSC screening output files..."
        
        # List all files in output directory
        echo "üìÅ Files in output directory:"
        ls -la output/ || echo "Output directory not found"
        
        # Check for the expected output files based on the script's naming convention
        csv_file="output/${OUTPUT_CSV%.*}_top5_targets.csv"
        report_file="output/${OUTPUT_CSV%.*}_analysis_report.txt"
        detailed_file="output/${OUTPUT_CSV%.*}_detailed_results.csv"
        
        echo "üîç Looking for files:"
        echo "  - CSV: $csv_file"
        echo "  - Report: $report_file" 
        echo "  - Detailed: $detailed_file"
        
        # Verify CSV file
        if [ -f "$csv_file" ]; then
          echo "‚úÖ CSV file created: $csv_file"
          ls -lh "$csv_file"
          echo "First 5 lines of CSV:"
          head -n 5 "$csv_file" || echo "Could not read CSV file"
        else
          echo "‚ùå CSV file not created: $csv_file"
          echo "Available CSV files:"
          find output/ -name "*.csv" -type f || echo "No CSV files found"
          exit 1
        fi
        
        # Verify analysis report
        if [ -f "$report_file" ]; then
          echo "‚úÖ Analysis report created: $report_file"
          ls -lh "$report_file"
          echo "Report summary (first 20 lines):"
          head -n 20 "$report_file" || echo "Could not read report file"
        else
          echo "‚ùå Analysis report not created: $report_file"
          echo "Available text files:"
          find output/ -name "*.txt" -type f || echo "No TXT files found"
          exit 1
        fi
        
        # Set outputs for next job
        echo "csv_file=$csv_file" >> $GITHUB_OUTPUT
        echo "report_file=$report_file" >> $GITHUB_OUTPUT
        echo "detailed_file=$detailed_file" >> $GITHUB_OUTPUT
        echo "output_file=$csv_file" >> $GITHUB_OUTPUT
        echo "successful=true" >> $GITHUB_OUTPUT

    - name: Upload screening results
      uses: actions/upload-artifact@v4
      with:
        name: ssc-pdb-screening-results
        path: |
          output/*_top5_targets.csv
          output/*_analysis_report.txt
        retention-days: 30

  commit-results:
    name: Commit Results to Repository
    runs-on: ubuntu-latest
    needs: [validate-input, run-pdb-screening]
    if: needs.run-pdb-screening.result == 'success'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1
        ref: main  # Ensure we're on the main branch

    - name: Download screening results
      uses: actions/download-artifact@v4
      with:
        name: ssc-pdb-screening-results
        path: ./

    - name: Organize output files
      run: |
        # Create output directory if it doesn't exist
        mkdir -p output
        
        # List what files were downloaded from artifact
        echo "üìÅ Files downloaded from artifact:"
        ls -la
        
        # Move CSV and TXT files to output directory
        if ls *_top5_targets.csv 1> /dev/null 2>&1; then
          cp *_top5_targets.csv output/
          echo "‚úÖ CSV file copied to output directory"
        fi
        
        if ls *_analysis_report.txt 1> /dev/null 2>&1; then
          cp *_analysis_report.txt output/
          echo "‚úÖ TXT report file copied to output directory"
        fi
        
        # Also copy the main output file if it exists
        if [ -f "$OUTPUT_CSV" ]; then
          cp "$OUTPUT_CSV" "output/"
          echo "‚úÖ Main output file copied to output directory"
        fi
        
        # List files in output directory
        echo "üìÅ Files in output directory:"
        ls -la output/
        
        # Create analysis report
        echo "# PDB Ligand Screening Analysis Report" > output/analysis_report.md
        echo "" >> output/analysis_report.md
        echo "**Generated:** $(date)" >> output/analysis_report.md
        echo "**Workflow Run:** ${{ github.run_number }}" >> output/analysis_report.md
        echo "**Commit:** ${{ github.sha }}" >> output/analysis_report.md
        echo "" >> output/analysis_report.md
        echo "## Summary" >> output/analysis_report.md
        echo "- **Total Processed:** ${{ needs.run-pdb-screening.outputs.total-processed }}" >> output/analysis_report.md
        echo "- **Successful Matches:** ${{ needs.run-pdb-screening.outputs.successful }}" >> output/analysis_report.md
        echo "- **Output File:** ${{ needs.run-pdb-screening.outputs.output-file }}" >> output/analysis_report.md
        echo "" >> output/analysis_report.md
        echo "## Input Files" >> output/analysis_report.md
        echo "- Input CSV: ${{ env.INPUT_CSV }}" >> output/analysis_report.md
        echo "- PDB Database: ${{ env.PDB_LIGANDS_FILE }}" >> output/analysis_report.md
        echo "" >> output/analysis_report.md
        echo "## Results" >> output/analysis_report.md
        echo "The screening results are available in the output directory." >> output/analysis_report.md

    - name: Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

    - name: Commit and push results
      run: |
        # Add results to git
        git add output/
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          # Pull remote changes first to avoid conflicts
          echo "Pulling latest changes from remote..."
          git pull --rebase origin main || {
            echo "‚ö†Ô∏è Rebase failed, trying merge strategy..."
            git pull origin main --no-rebase || {
              echo "‚ùå Failed to pull remote changes"
              exit 1
            }
          }
          
          # Re-add files in case rebase/merge affected them
          git add output/
          
          # Check again if there are still changes to commit after pull
          if git diff --staged --quiet; then
            echo "No changes to commit after pulling remote updates"
          else
            git commit -m "üß¨ Add PDB screening results - Run ${{ github.run_number }}

            - Processed: ${{ needs.run-pdb-screening.outputs.total-processed }} chemicals
            - Successful: ${{ needs.run-pdb-screening.outputs.successful }} matches
            - Generated: $(date)
            - Workflow: ${{ github.workflow }}
            - Commit: ${{ github.sha }}"
            
            # Try to push with retry logic
            for i in {1..3}; do
              echo "Push attempt $i/3..."
              if git push; then
                echo "‚úÖ Results committed and pushed to repository"
                break
              else
                if [ $i -lt 3 ]; then
                  echo "Push failed, pulling again and retrying..."
                  git pull --rebase origin main || git pull origin main --no-rebase
                  sleep 2
                else
                  echo "‚ùå Failed to push after 3 attempts"
                  exit 1
                fi
              fi
            done
          fi
        fi

  generate-summary:
    name: Generate Workflow Summary
    runs-on: ubuntu-latest
    needs: [validate-input, run-pdb-screening, commit-results]
    if: always()
    
    steps:
    - name: Generate summary
      run: |
        echo "# üß¨ PDB Ligand Screening Workflow Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Workflow Run:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "**Triggered by:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
        echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "## üìã Job Status" >> $GITHUB_STEP_SUMMARY
        echo "- **Validation:** ${{ needs.validate-input.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Screening:** ${{ needs.run-pdb-screening.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Commit Results:** ${{ needs.commit-results.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ needs.run-pdb-screening.result }}" == "success" ]; then
          echo "## üéØ Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Processed:** ${{ needs.run-pdb-screening.outputs.total-processed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Successful Matches:** ${{ needs.run-pdb-screening.outputs.successful }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Output File:** ${{ needs.run-pdb-screening.outputs.output-file }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ **Screening completed successfully!**" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå **Screening failed or was skipped**" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## üìÅ Files" >> $GITHUB_STEP_SUMMARY
        echo "- Input: ${{ env.INPUT_CSV }}" >> $GITHUB_STEP_SUMMARY
        echo "- PDB Database: ${{ env.PDB_LIGANDS_FILE }}" >> $GITHUB_STEP_SUMMARY
        echo "- Output: ${{ env.OUTPUT_CSV }}" >> $GITHUB_STEP_SUMMARY
